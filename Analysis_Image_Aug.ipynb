{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7051cd-de45-4748-a76f-8acf8c1966fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyizing Malignant / Benign tissues\n",
    "\n",
    "Purpose of Level 4 Analysis_May26:\n",
    "* Analysis includes:\n",
    "    * Segmentation with MATLAB script run \n",
    "\n",
    "Purpose of Level 3 Analysis:\n",
    "* Analysis includes:\n",
    "    * Includes TZ and PZ analysis\n",
    "    * Analyzes based off GS\n",
    "    * normalizing, standardizing, both (1: normalize, 2: standardize)\n",
    "    * removes when pixels, say LWF = 0\n",
    "    * Weights images with multiplication factor\n",
    "    * Weights HR images based on "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d3e54-7636-454b-ab35-2008f69d7dad",
   "metadata": {},
   "source": [
    "## Imports & User File Locations Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50976f24-aeb0-4d58-b27c-9e12250f92f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Imports for the function to run'''\n",
    "\n",
    "# %matplotlib widget\n",
    "%matplotlib inline \n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "from scipy.io import loadmat\n",
    "from skimage.transform import resize as ski_resize\n",
    "import cv2\n",
    "import copy\n",
    "import seaborn as sns # for plotting w/ multiple y-axis (just two)\n",
    "import math\n",
    "import imageio\n",
    "import matplotlib.patches as mpatches\n",
    "import matlab.engine \n",
    "\n",
    "'''Selection of user definted inputs\n",
    "    Including: \n",
    "        - folder inputs for ROIs\n",
    "        - folder containing the analyzed data i.e. LWI maps '''\n",
    "\n",
    "# Possible ROI folders to choose from (can be .mat or .png)\n",
    "# -- ROI folders (drawn)\n",
    "folderFullRois =     \"C:/Users/candi/Documents/Research/1 LWI Project/1 Data/2 ROIs/CombinedROIs/Full\"\n",
    "folderPZRois =       \"C:/Users/candi/Documents/Research/1 LWI Project/1 Data/2 ROIs/CombinedROIs/PZ\"\n",
    "folderPZMaligRois =  \"C:/Users/candi/Documents/Research/1 LWI Project/1 Data/2 ROIs/CombinedROIs/PZM\"\n",
    "# -- ROI folders (predicted & subset of patients)\n",
    "folderPZml =         \"C:/Users/candi/Documents/Research/1 LWI Project/1 Data/7 Model Outputs/20210726_2231_UNETv2_cuda_PZ_test/Predicted_k3\"\n",
    "folderFullml =       \"C:/Users/candi/Documents/Research/1 LWI Project/1 Data/7 Model Outputs/20210718_1813_UNET_cpu_full_test/Predicted_k3\"\n",
    "# -- Gleason Score map\n",
    "folder_gs =           \"C:/Users/candi/Documents/Research/1 LWI Project/1 Data/2 ROIs/CombinedROIs/GSMap\"\n",
    "\n",
    "# Selecting the folder for ROI\n",
    "folder_roi = folderFullRois\n",
    "folder_pz = folderPZRois\n",
    "# folder_roi = folderFullml\n",
    "# folder_pz = folderPZml\n",
    "\n",
    "\n",
    "# -- LWI maps \n",
    "folder_nnls_matlab = 'C:/Users/candi/Documents/Research/1 LWI Project/1 Data/8 NNLS Output/NNLS_matlab/LWI_nomask_Matlab(1)'\n",
    "folder_nnls_decaes = 'C:/Users/candi/Documents/Research/1 LWI Project/1 Data/8 NNLS Output/DECAES_qt2'\n",
    "#'C:/Users/candi/Documents/Research/1 LWI Project/1 Data/8 NNLS Output/DECAES_matlab/LWI_matlab'\n",
    "\n",
    "# -- T2 Decay data\n",
    "T2Decay_data_folder = 'C:/Users/candi/Documents/Research/1 LWI Project/1 Data/3 T2 Decay'\n",
    "\n",
    "# -- High-Res T2w (512 x 512) Image data\n",
    "HR_T2W_data_folder = 'C:/Users/candi/Documents/Research/1 LWI Project/1 Data/4 HighRes/High Res Mat'\n",
    "\n",
    "# -- Location to save information in\n",
    "folderOutputIms =    \"C:/Users/candi/Documents/Research/1 LWI Project/3 Python Scripts/JupyterLab/Analysis/Analysis_level3\"\n",
    "\n",
    "# --- Setting colormap of images to always be gray\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f57f6-e5ec-4433-b732-e6f5397f610e",
   "metadata": {},
   "source": [
    "## Functions required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be6158-0c3b-4fd4-9a82-fa0a670cbcfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------        \n",
    "# ----- load_P_S\n",
    "# --------------------------------\n",
    "def load_P_S(lwiPath, folder_roi, folder_pz, folder_gs, pnum, snum):\n",
    "    \"\"\" A function to load ROI and LWI data based on patient number and string\n",
    "        Requires that the structure of the files are \"P(#patient number)_S(#slice number).mat\"\n",
    "        Inputs:\n",
    "            - lwiPath:      path to the LWI file folders (str)\n",
    "            - folder_roi:   path to the full ROI file folders (str) \n",
    "            - folder_pz:    path to the PZ ROI files (str)\n",
    "            - folder_gs:    path to the ROI files that malignancy levels based on GS (str)\n",
    "            - pnum:         patient number (int)\n",
    "            - snum:         slice number (int)\n",
    "        Returns:\n",
    "            - LWI:        the file with LWI information\n",
    "            - fields:     string set with object names the LWIL file contains\n",
    "            - roi:        the ROI corresponding to the LWI dataset returned\n",
    "            - roiPZ:      the ROI corresponding to peripheral zone\n",
    "            - roiTZ:      the ROI corresponding to transition zone\n",
    "            - roiGS:      the malignant ROI corresponding to the LWI dataset returned\"\"\"    \n",
    "    fields,lwi = loadDecaesOrMatlab(lwiPath, pnum, snum) # obtaining the fields and LWI dataset (decaes or NNLS)\n",
    "#     roi, roiM = loadROI(roiPath, roiMaligPath, pnum, snum)\n",
    "    roi_all, roi_pz, roi_tz, gs_map = loadROIall(folder_roi,folder_pz,folder_gs,pnum,snum)\n",
    "#     # filtering out LWF = 0 through redrawing roi ********************************************************************************************************************* temp!\n",
    "#     roi[np.where(np.isclose(lwi['LWF'], 0))] = False\n",
    "#     roiM[np.where(np.isclose(lwi['LWF'], 0))] = False\n",
    "    \n",
    "    return fields, lwi, roi_all, roi_pz, roi_tz, gs_map\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- loadROI\n",
    "# --------------------------------\n",
    "def loadROIall(folder_roi, folder_pz, folder_gs, pnum, snum):\n",
    "    \"\"\"A function to load the ROIs of the file given the patient number and slice number\n",
    "       Inputs:\n",
    "           - folder_roi:   path to the full ROI file folders (str) \n",
    "           - folder_pz:    path to the PZ ROI files (str)\n",
    "           - folder_gs:    path to the ROI files that malignancy levels based on GS (str)\n",
    "           - pnum:   patient number (int)\n",
    "           - snum:   slice number (int)\n",
    "       Returns:\n",
    "           - roi:    ROI for the entire zone [bool]\n",
    "           - roi_pz: the ROI for peripheral zone [bool]\n",
    "           - roi_tz: the ROI for transition zone [bool]\n",
    "           - gs_map: a map outline gleason grading in the slice\"\"\"\n",
    "    # Determining the type of ROI's whether they are .mat or in .png format and loading. (All ROI)\n",
    "    try:\n",
    "        if glob.glob(folder_roi + '/P*' + str(pnum) + '_S*' + str(snum) + '*')[0].find('.mat') >0:\n",
    "            roi = loadmat(glob.glob(folder_roi + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')[0])\n",
    "            roi = roi[list(roi.keys())[3]]\n",
    "        elif glob.glob(folder_roi + '/P*' + str(pnum) + '_S*'+ str(snum) + '*')[0].find('.png') >0:\n",
    "            roi = cv2.imread(glob.glob(folder_roi + '/P*' + str(pnum) + '_S*' + str(snum) + '*.png')[0])\n",
    "            roi = roi[:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Error:  Problem reading ROI folder: ' + glob.glob(path + '/P*' + str(p) + '_S*')[0])\n",
    "    except:\n",
    "        print('Error:  All ROI file (P' + str(pnum) + '_S' + str(snum) + 'could not be found: ' + folder_roi + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')\n",
    "        raise\n",
    "\n",
    "\n",
    "    # Determining the type of ROI's whether they are .mat or in .png format and loading. (PZ ROI)\n",
    "    try:\n",
    "        if glob.glob(folder_pz + '/P*' + str(pnum) + '_S*' + str(snum) + '*')[0].find('.mat') >0:\n",
    "            roi_pz = loadmat(glob.glob(folder_pz + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')[0])\n",
    "            roi_pz = roi_pz[list(roi_pz.keys())[3]]\n",
    "        elif glob.glob(folder_pz + '/P*' + str(pnum) + '_S*'+ str(snum) + '*')[0].find('.png') >0:\n",
    "            roi_pz = cv2.imread(glob.glob(folder_pz + '/P*' + str(pnum) + '_S*' + str(snum) + '*.png')[0])\n",
    "            roi_pz = roi_pz[:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Error:  Problem reading ROI folder: ' + glob.glob(path + '/P*' + str(p) + '_S*')[0])\n",
    "    except:\n",
    "        print('Error:  PZ ROI file (P' + str(pnum) + '_S' + str(snum) + 'could not be found: ' + folder_pz + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')\n",
    "        raise\n",
    "\n",
    "    # Loading GS map\n",
    "    try:\n",
    "        if glob.glob(folder_gs + '/P*' + str(pnum) + '_S*' + str(snum) + '*')[0].find('.mat') >0:\n",
    "            gs_map = loadmat(glob.glob(folder_gs + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')[0])\n",
    "            gs_map = gs_map[list(gs_map.keys())[3]]\n",
    "        else:\n",
    "            raise ValueError('Error:  Problem reading ROI folder: ' + glob.glob(path + '/P*' + str(p) + '_S*')[0])\n",
    "    except:\n",
    "        print('Error:  GS Map file (P' + str(pnum) + '_S' + str(snum) + 'could not be found: ' + folder_gs + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')\n",
    "        raise\n",
    "\n",
    "    if roi_pz is not None:\n",
    "        roi_tz = cleanROI(roi.astype(bool) & ~roi_pz.astype(bool))\n",
    "        \n",
    "    return roi.astype(bool), roi_pz.astype(bool), roi_tz.astype(bool), gs_map\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- loadROI\n",
    "# --------------------------------\n",
    "def loadROI(path, pathM, pnum, snum):\n",
    "    \"\"\"A function to load the ROIs of the file given the patient number and slice number\n",
    "       Inputs:\n",
    "           - path:   a path for where the ROI files are located (str)\n",
    "           - pathM:  a path for the malignant ROI files location (str_)\n",
    "           - pnum:   patient number (int)\n",
    "           - snum:   slice number (int)\n",
    "       Returns:\n",
    "           - roi:  ROI for the entire zone [bool]\n",
    "           - roiM: the ROI for the malignant pixels given a patient + slice  [bool]\"\"\"\n",
    "    # Determining the type of ROI's whether they are .mat or in .png format\n",
    "    try:\n",
    "        if glob.glob(path + '/P*' + str(pnum) + '_S*' + str(snum) + '*')[0].find('.mat') >0:\n",
    "            roi = loadmat(glob.glob(path + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')[0])\n",
    "            roi = roi[list(roi.keys())[3]]\n",
    "        elif glob.glob(path + '/P*' + str(pnum) + '_S*'+ str(snum) + '*')[0].find('.png') >0:\n",
    "            roi = cv2.imread(glob.glob(folder_roi + '/P*' + str(pnum) + '_S*' + str(snum) + '*.png')[0])\n",
    "            roi = roi[:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Error:  Problem reading ROI folder: ' + glob.glob(path + '/P*' + str(p) + '_S*')[0])\n",
    "    except:\n",
    "        print('Error:  ROI file (P' + str(pnum) + '_S' + str(snum) + 'could not be found: ' + path + '/P*' + str(pnum) + '_S*' + str(snum) + '*.mat')\n",
    "        raise\n",
    "    \n",
    "    # Determining the type of malignant ROI's whether they are .mat or in .png format\n",
    "    # Does not raise an exception because not all rois contain malignancy! If so, the mask will be all false\n",
    "    try: \n",
    "        if glob.glob(pathM + '/P*' + str(pnum) + '_S' + str(snum) + '*')[0].find('.mat') >0:\n",
    "            roiM = loadmat(glob.glob(pathM + '/P*' + str(pnum) + '_S' + str(snum) + '*.mat')[0])\n",
    "            roiM = roiM[list(roiM.keys())[3]]\n",
    "        elif glob.glob(pathM + '/P*' + str(pnum) + '_S' + str(snum) + '*')[0].find('.png') >0:\n",
    "            roiM = cv2.imread(glob.glob(pathM + '/P*' + str(pnum) + '_S' + str(snum) + '*.png')[0])\n",
    "            roiM = roiM[:,:,0]\n",
    "    except:\n",
    "        roiM = np.zeros(np.shape(roi))\n",
    "    \n",
    "    return roi.astype(bool), roiM.astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- loadDecaesOrMatlab\n",
    "# --------------------------------\n",
    "def loadDecaesOrMatlab(path, pnum, snum):\n",
    "    \"\"\"A function to determine whether the path is directed to the DECAES LWI data or NNLS and return\n",
    "       the objects and the file itself.\n",
    "       Inputs:\n",
    "           - path:   a path for where the files are located (str)\n",
    "           - pnum:       patient number (int)\n",
    "           - snum:       slice number (int)\n",
    "       Returns:\n",
    "           - fields: string set with object names the LWIL file contains depending on NNLS or DECAES analysis\n",
    "           - lwi:    the LWI file with the maps\"\"\" \n",
    "    lwipath = path + '/P*' +  str(pnum) + '*.mat'\n",
    "    try:\n",
    "        if 'results' in h5py.File(glob.glob(lwipath)[0]):\n",
    "            if len(glob.glob(path + '/P*' +  str(pnum) + '_S*' + str(snum) + '.mat')) > 0: # loading matlab data\n",
    "                lwi = reorder_h5py(h5py.File(glob.glob(path + '/P*' +  str(pnum) + '_S*' + str(snum) + '.mat')[0])['results'],snum)\n",
    "            elif len(glob.glob(path + '/P*' +  str(pnum) + '*.mat')) > 0: # loading decaes, 7 param (nnls) data\n",
    "                lwi = reorder_h5py(h5py.File(glob.glob(path + '/P*' + str(pnum) + '*.mat')[0])['results'],snum)\n",
    "                \n",
    "        else:\n",
    "            lwi = reorder_h5py(h5py.File(glob.glob(path + '/P*' + str(pnum) + '*t2parts.mat')[0]),snum)\n",
    "            lwi = {**lwi,**(reorder_h5py(h5py.File(glob.glob(path + '/P*' + str(pnum) + '*t2maps.mat')[0]),snum))} # adding two dictionaries together\n",
    "    except: \n",
    "        print('Error:  No LWI map found for P' + str(pnum) + '_S' + str(snum) + ' given path: ' + path)\n",
    "        raise\n",
    "    fields = list(lwi.keys())\n",
    "    return fields, lwi\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- cleanROI\n",
    "# --------------------------------\n",
    "def cleanROI(roi):\n",
    "    \"\"\" Removes small islands outside of ROI\n",
    "    Input:\n",
    "        - roi: the binary, boolean ROI that will be edited\n",
    "    Returns:\n",
    "        - cleaned_roi: the binary, boolean ROI that with small islands removed\"\"\"\n",
    "    contours,_ = cv2.findContours((np.uint8(roi)), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cmax = max(contours, key = cv2.contourArea) \n",
    "    epsilon = 0.002 * cv2.arcLength(cmax, True)\n",
    "    approx = cv2.approxPolyDP(cmax, epsilon, True)\n",
    "\n",
    "    width, height = (np.uint8(roi)).shape\n",
    "\n",
    "    #fill maximum contour and draw   \n",
    "    img = np.zeros( [width, height, 3],dtype=np.uint8 )\n",
    "    cv2.fillPoly(img, pts =[cmax], color=(255,255,255))\n",
    "    cleaned_roi = img[:,:,0].astype(bool)\n",
    "    return cleaned_roi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- reorder_h5py\n",
    "# --------------------------------\n",
    "def reorder_h5py(h5py_data,s):\n",
    "    \"\"\"h5py has a different ordering than what python does, so images are flipped. \n",
    "       this function reorders the data as expected. Requires a transpose and a conversion to numpy array.\n",
    "       i.e. 2D data as (nrows,ncols)\n",
    "       Inputs:\n",
    "           - h5py_data:  h5py datatype for image arrays  \n",
    "           - s:          slice number as an int  \n",
    "       Returns:\n",
    "           - ordered:     a dict pair of parameter and a nrow x ncol image (slice has been pre selected)\"\"\"\n",
    "    ordered = dict()   \n",
    "    for keyz in h5py_data.keys():\n",
    "        ordered[keyz] = np.ascontiguousarray(h5py_data[keyz]).transpose()\n",
    "        if ordered[keyz].ndim == 3:\n",
    "            ordered[keyz] = ordered[keyz][:,:,s]\n",
    "    return ordered\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- loadHR_T2W\n",
    "# --------------------------------\n",
    "def loadHR_T2W(path, pnum, snum):\n",
    "    \"\"\"A function to determine whether the path is directed to the DECAES LWI data or NNLS and return\n",
    "       the objects and the file itself.\n",
    "       Inputs:\n",
    "           - path:   a path for where the files are located (str)\n",
    "           - pnum:   patient number (int)\n",
    "           - snum:    slice number (int)\n",
    "       Returns:\n",
    "           - HR_img: a image 512x512 for the given patient and slice (np array)\"\"\" \n",
    "    hrpath = path + '/P*' +  str(pnum) + '*.mat'\n",
    "    T2W_18 = loadmat(glob.glob(hrpath)[0])['T2W']\n",
    "    HR_img = T2W_18[:,:,snum]\n",
    "    return HR_img\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- plotGif3D\n",
    "# --------------------------------  \n",
    "def plotGif3D(saveName, ax, anglesMulti, step=2):\n",
    "    \"\"\" Creates gif through varying angles \n",
    "    Input:\n",
    "        - saveName:    the name of the gif\n",
    "        - ax:          the plot axis\n",
    "        - anglesMulti: a 2D numpy array of the angles to be followed\n",
    "        - step:        step size between each angle plotted\n",
    "    \"\"\"\n",
    "    \n",
    "    images = []\n",
    "    # initializing the view\n",
    "    ax.view_init(anglesMulti[0][0],anglesMulti[0][1])\n",
    "    \n",
    "    # saving gif\n",
    "    if saveName is not None:\n",
    "        # looping through each angle\n",
    "        for i in range(len(anglesMulti)-1):\n",
    "            angle1 = np.arange(anglesMulti[i][0],anglesMulti[i+1][0],2)\n",
    "            angle2 = np.arange(anglesMulti[i][1],anglesMulti[i+1][1],2)\n",
    "\n",
    "            numi = np.max([len(angle1),len(angle2)])\n",
    "            if len(angle1) == 0:\n",
    "                angle1 = np.ones(numi)*anglesMulti[i][0]\n",
    "            if len(angle2) == 0:\n",
    "                angle2 = np.ones(numi)*anglesMulti[i][1]\n",
    "\n",
    "            # changing view and appending images\n",
    "            for j in range(numi):\n",
    "                ax.view_init(angle1[j],angle2[j])\n",
    "                plt.savefig('saved_figure_' + '.png')\n",
    "                images.append(imageio.imread('saved_figure_' + '.png'))\n",
    "                os.remove('saved_figure_' + '.png')\n",
    "            \n",
    "            # saving image\n",
    "            imageio.mimsave(saveName, images, fps=24)\n",
    "    return\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- printParamsAllROIs\n",
    "# --------------------------------  \n",
    "def printParamsAllROIs(T2DecayPath, echo, lwiPath, folder_roi, folder_pz, folder_gs, pnum, snum, parameters, cname='cubehelix', save = False, analysisType=None):\n",
    "    \"\"\"A function to print the slice and patient on screen\n",
    "       Inputs:\n",
    "            - T2DecayPath:  path to T2 decay data (str)     \n",
    "            - echo:         the echo number to get image from (int)\n",
    "            - lwiPath:      path to the LWI file folders (str)\n",
    "            - folder_roi:   path to the full ROI file folders (str) \n",
    "            - folder_pz:    path to the PZ ROI files (str)\n",
    "            - folder_gs:    path to the ROI files that malignancy levels based on GS (str)\n",
    "            - snum:         slice number (int)\n",
    "            - parameters:   the parameters selected for analysis e.g. LWF, sgm, mfr, etc. (list)\n",
    "            - cname:        the seaborn colour palette to use\n",
    "            - save:         to save or not save the file\n",
    "            - analysisType: the type of analysis\"\"\"\n",
    "\n",
    "    # loading T2 decay \n",
    "    T2Decay = loadmat(glob.glob(T2Decay_data_folder + '/P' + str(pnum).zfill(3) + '_cmplx*.mat')[0])\n",
    "    T2Decay = T2Decay[list(T2Decay.keys())[3]] # usually always the third item in loadmat!\n",
    "\n",
    "    # T2 decay\n",
    "    img_decay=T2Decay[:,:,snum,echo] # the decay image\n",
    "\n",
    "    # obtaining the fields and LWI dataset (decaes or NNLS) & the ROIs for the data and the malignant ROI\n",
    "    fields, lwi, roi, roi_pz, roi_tz, gs_map = load_P_S(lwiPath, folder_roi, folder_pz, folder_gs, pnum, int(snum))\n",
    "    \n",
    "    # setting defaults for figure\n",
    "    plt.rcParams['figure.figsize'] = (15,50) # set default size of plots\n",
    "    plt.rcParams['image.cmap'] = 'gray'\n",
    "    plt.figure()\n",
    "    f,ax = plt.subplots(len(parameters)+1,2)\n",
    "    \n",
    "    # T2W image\n",
    "    ax[0,0].imshow(img_decay)\n",
    "    ax[0,0].set_title('T2W (' + str(np.size(img_decay,0)) + 'x' + str(np.size(img_decay,1)) + ')')\n",
    "    ax[0,0].axis('off')\n",
    "    \n",
    "    # Getting GS and ROIs\n",
    "#     colours = plt.cm.Set1(np.linspace(0,1,8))\n",
    "#     colours = colours[:,0:3]\n",
    "    colours = np.array(sns.color_palette(palette=cname, n_colors=8))\n",
    "    # getting oultines\n",
    "    pz_outline = outlineROI(roi_pz.astype(img_decay[0,0])).astype(bool)\n",
    "    tz_outline = outlineROI(roi_tz).astype(img_decay[0,0]).astype(bool)\n",
    "    baseim = np.dstack([(normalize(img_decay)),(normalize(img_decay)),(normalize(img_decay))]) # 3d image\n",
    "    for c in range(6):\n",
    "        baseim[(roi_pz|roi_tz)&(gs_map==c+1),:] = colours[c+2,:] # getting gs\n",
    "    # making legend\n",
    "    gs_labels = ['pz','tz','3+3','3+4','4+3','4+4','4+5','5+4']\n",
    "    legend_dict=dict(zip(gs_labels,colours))\n",
    "    #create patches\n",
    "    patchList = []\n",
    "    for key in legend_dict:\n",
    "        data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
    "        patchList.append(data_key)\n",
    "    # putting roi ontop \n",
    "    baseim[pz_outline,:] = colours[0,:] # getting pz outline\n",
    "    baseim[tz_outline,:] = colours[1,:] # getting tz outline\n",
    "    ax[0,1].imshow(baseim)\n",
    "    ax[0,1].set_title('Gleason Scores & zones')\n",
    "    ax[0,1].axis('off')\n",
    "    ax[0,1].legend(handles=patchList, fontsize='small')\n",
    "\n",
    "    \n",
    "    # Plotting parameters and overlaid gleason score\n",
    "    for param in parameters: \n",
    "        # first image: image parameters\n",
    "        lwi2 = copy.deepcopy(lwi) # deep copy to copy the image\n",
    "        lwi2[param][~roi] = np.nan # remove all other parts of the image except ROI\n",
    "        im1=ax[parameters.index(param)+1,0].imshow(lwi2[param])\n",
    "        ax[parameters.index(param)+1,0].set_title('S:' + str(snum) + ' P' + str(pnum) + ', Param: ' + param, size=15)\n",
    "        ax[parameters.index(param)+1,0].axis('off')\n",
    "        plt.colorbar(im1, ax=ax[parameters.index(param)+1,0])\n",
    "        # second image: overlaid with weight\n",
    "        curIm = copy.deepcopy(lwi[param])\n",
    "        curIm = np.dstack([normalize(curIm),normalize(curIm),normalize(curIm)])\n",
    "        blankIm = np.zeros([np.size(img_decay,0),np.size(img_decay,1),3])\n",
    "        for c in range(6):\n",
    "            blankIm[(roi_pz|roi_tz)&(gs_map==c+1),:] = colours[c+2,:] # getting gs\n",
    "        secondIm =cv2.addWeighted(blankIm,0.3,curIm,0.7,0.0)\n",
    "        secondIm[~roi] = np.nan\n",
    "        im2=ax[parameters.index(param)+1,1].imshow(secondIm)\n",
    "        ax[parameters.index(param)+1,1].set_title('Showing Gleason Score. S:' + str(snum) + ' P' + str(pnum) + ', Param: ' + param, size=15)\n",
    "        ax[parameters.index(param)+1,1].axis('off')\n",
    "        ax[parameters.index(param)+1,1].legend(handles=patchList[2:], fontsize='small')\n",
    "        ax[parameters.index(param)+1, 1].axis('off')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('P' + str(pnum)+ '_S'+ str(snum) + '_' + analysisType+ '.png')\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def makeDir(bpath):\n",
    "    \"\"\"Makes a new, non-overwriting folder (makes a new folder name if name already exists), returns path of folder\"\"\"\n",
    "    path=bpath\n",
    "    pathMade=False\n",
    "    numPath=1\n",
    "    while not(pathMade):\n",
    "        try:\n",
    "            os.makedirs(path, exist_ok=False)\n",
    "            pathMade = True\n",
    "        except:\n",
    "            path=bpath+str(numPath)\n",
    "            numPath+=1\n",
    "    return path\n",
    "\n",
    "def init_excel(colNames, sheetName='Sheet1'):\n",
    "    book = xlwt.Workbook()\n",
    "    sheet = book.add_sheet(sheetName)\n",
    "    for column, heading in enumerate(colNames):\n",
    "        sheet.write(0, column, heading)\n",
    "    return book,sheet\n",
    "\n",
    "def excel_output(sheet, colNames, row2print):  \n",
    "    nextRow = len(sheet._Worksheet__rows)\n",
    "    \n",
    "    for i,column in enumerate(colNames):\n",
    "        sheet.write(nextRow, i, row2print[column])\n",
    "\n",
    "    return sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc83a9-f7f7-407a-9783-de970413c5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getCompiledData(lwi, norm, dataCompile, benignCompile, maligCompile, roi_zone, gs_map, par, printGraphs=False, pnum=None,snum=None, ax=None, axNum=None, colours=None):    \n",
    "    \"\"\" Compiles the data as pixels for all data, benign and malignant\n",
    "    Inputs:\n",
    "        - lwi\n",
    "        - norm\n",
    "        - dataCompile\n",
    "        - benignCompile\n",
    "        - maligCompile\n",
    "        - roi_zone\n",
    "        - gs_map\n",
    "        - parameters\n",
    "        - printGraphs=False\n",
    "        - pnum\n",
    "        - snum\n",
    "        - ax=None\n",
    "        - colours\n",
    "    Returns:\n",
    "        - dataCompile\n",
    "        - benignCompile\n",
    "        - oneMaligCompile \"\"\"\n",
    "    # Getting roiB and dictionary roiM\n",
    "    roiB, roiMdict = splitGS_roi(roi_zone, gs_map)\n",
    "    \n",
    "    # For visualizing (1/3)\n",
    "    if printGraphs:\n",
    "        printIm = copy.deepcopy(lwi[par])\n",
    "        printIm[~roiB] = np.nan\n",
    "        # Getting GS and ROIs\n",
    "        # getting oultines\n",
    "        roi_outline = outlineROI(roi_zone.astype(np.float64)).astype(bool)\n",
    "        baseim = np.dstack([(normalize(printIm)),(normalize(printIm)),(normalize(printIm))]) # 3d image\n",
    "        for c in range(6):\n",
    "            baseim[(roi_zone)&(gs_map==c+1),:] = colours[c+2,:] # getting gs\n",
    "        # making legend\n",
    "        gs_labels = ['pz','tz','3+3','3+4','4+3','4+4','4+5','5+4']\n",
    "        legend_dict=dict(zip(gs_labels,colours))\n",
    "        #create patches\n",
    "        patchList = []\n",
    "        for key in legend_dict:\n",
    "            data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
    "            patchList.append(data_key)\n",
    "        # putting roi ontop \n",
    "        baseim[roi_outline,:] = colours[0,:] # getting pz outline\n",
    "        ax[0,axNum].imshow(baseim)\n",
    "        ax[0,axNum].set_title('P' + str(pnum) + ' S' + str(slice1) + ', Param: ' + par, size=15)\n",
    "        ax[0,axNum].axis('off')\n",
    "        ax[0,axNum].legend(handles=patchList, fontsize='small')\n",
    "        ax[0,axNum].axis('off')\n",
    "        # Histograms\n",
    "        sns.histplot(lwi[par][roiB], color='dodgerblue', alpha=0.4,ax=ax[1,axNum],kde=True)\n",
    "        for m in roiMdict:\n",
    "            sns.histplot(lwi[par][roiMdict[m]], color = colours[m+2,:],alpha=0.4,ax=ax[1,axNum],kde=True)\n",
    "        patchListHist = patchList[2:]\n",
    "        patchListHist.append(mpatches.Patch(color='dodgerblue', label='benign'))\n",
    "        ax[1,axNum].legend(handles=patchListHist,fontsize='small')\n",
    "\n",
    "    # Normalizing data if chosen\n",
    "    if norm == 'standardize':\n",
    "        if par != 'N':\n",
    "            lwi[par] = standardize(lwi[par])\n",
    "    elif norm == 'normalize':\n",
    "        if par != 'N':\n",
    "            lwi[par] = normalize(lwi[par])\n",
    "    elif norm == 'both':\n",
    "        if par != 'N':\n",
    "            lwi[par] = normalize(lwi[par])\n",
    "            lwi[par] = standardize(lwi[par])\n",
    "    tempDataCompile = copy.deepcopy(lwi[par])\n",
    "    tempDataCompile[~roi_zone] = np.nan\n",
    "    dataCompile[par] = np.concatenate((dataCompile[par],tempDataCompile[roi_zone]),axis=0)\n",
    "\n",
    "    tempBenignCompile = copy.deepcopy(lwi[par])\n",
    "    tempBenignCompile[~roiB] = np.nan\n",
    "    benignCompile[par] = np.concatenate((benignCompile[par],tempBenignCompile[roi_zone]),axis=0)\n",
    "    \n",
    "    oneSliceMaligCompile = dict.fromkeys(np.arange(6),np.empty([0]))\n",
    "    for m in roiMdict:\n",
    "        tempMaligCompile = copy.deepcopy(lwi[par])\n",
    "        tempMaligCompile[~roiMdict[m]] = np.nan\n",
    "#         maligCompile[m][par] = np.concatenate((maligCompile[m][par],tempMaligCompile[roi_zone]),axis=0)\n",
    "        oneSliceMaligCompile[m] = tempMaligCompile[roi_zone]\n",
    "    return dataCompile, benignCompile, oneSliceMaligCompile\n",
    "\n",
    "\n",
    "def splitGS_roi(roi2split, GSmap):\n",
    "    \"\"\" Takes an incoming roi and splits it based on the GS score--> there are 6: '3+3','3+4','4+3','4+4','4+5','5+4\n",
    "    Input:\n",
    "        - roi2split: the roi [boolean]\n",
    "        - GSmap:     the Gleason Score map with integer values of [0,6] where each int corresponds to a GS score: '0','3+3','3+4','4+3','4+4','4+5','5+4'\n",
    "    Output:\n",
    "        - roiB:    the benign roi [bool]\n",
    "        - roiGS:   the rois split by GS as a dictionary. 0-->'3+3', 1--> '3+4', etc. [dict]\"\"\"\n",
    "    \n",
    "    # obtaining a copy of the \n",
    "    roi_r = copy.deepcopy(roi2split)\n",
    "    # getting benign roi\n",
    "    roiB = roi_r&~(GSmap>0)\n",
    "    # getting malignant roi's split by GS\n",
    "    roiGS = dict()\n",
    "    for i in range(6):\n",
    "        roiGS[i] = (roi_r)&(GSmap==i+1)\n",
    "        \n",
    "    return roiB, roiGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b8855-b701-4bd9-bc25-6838ee5ded00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------        \n",
    "# ----- load_single_patient_datacompile\n",
    "# --------------------------------  \n",
    "def load_single_patient_datacompile1(lwiPath, folder_roi, folder_pz, folder_gs, zone, pnum, slice1, parameters, norm=None, printGraphs=False, cname=None, bins=[100,100], save=False,analysisType=None):\n",
    "    \"\"\" Loads the matlab or decaes matlab data and compiles all the data from one patient and its relevant slice files based on an roi. Provides the malignant/benign data\n",
    "    Inputs:\n",
    "        - lwiPath:      path to the LWI file folders (str)\n",
    "        - folder_roi:   path to the ROI file folders (str) \n",
    "        - folder_pz:    path to the ROI files that pz (str)\n",
    "        - folder_gs:    path to the GS mapping (str)\n",
    "        - zone:         the data to analyze\n",
    "        - pnum:         patient number (int)\n",
    "        - slice1:       slice to analyze (int)\n",
    "        - parameters:   the parameters selected for analysis e.g. LWF, sgm, mfr, etc. (list)\n",
    "        - norm:         normalize the values before concatenating (either standardize, normalize, or both)\n",
    "        - printGraphs:  prints the relevant graphs to visiualize the parameters and histogram of malig vs benign\n",
    "        - cname:        the seaborn colour palette to use\n",
    "        - bins:         Histogram bins\n",
    "        - save:         to save the plots or not\n",
    "        - analysisType: either 'decaes' or 'matlab'\n",
    "    Returns:\n",
    "        - dataCompile:   a dictionary with each parameter value as dictionaries and keys of column data: all pixel data given in the mask (roiPath) for each slice of a patient. Size: [#params, len of dataCompile]\n",
    "        - labels:        a 1D array where 1 = malignant, 0 = benign\n",
    "        - benignCompile: a dictionary with each parameter value as dictionaries and keys of column data: benign data given in the mask (~roiMaligPath&roiPath) for each slice of a patient. Size: [#params, len of dataCompile]\n",
    "        - maligCompile:  a dictionary with each parameter value as dictionaries and keys of column data: benign data given in the mask (roiMaligPath&roiPath) for each slice of a patient. Size: [#params, len of dataCompile]\"\"\"\n",
    "    %matplotlib inline\n",
    "    patdirs = glob.glob(folder_roi+'/P*' + str(pnum) + '*') # getting the files that contain the patient number for the ROIs\n",
    "    slices = [] # array that carries the slices available for the patient\n",
    "    dataCompile = dict.fromkeys(parameters,np.empty([0]))\n",
    "    benignCompile = dict.fromkeys(parameters,np.empty([0]))\n",
    "    maligCompile = dict.fromkeys(parameters,dict.fromkeys(np.arange(6),np.empty([0])))\n",
    "    # maligCompile = dict.fromkeys(parameters,np.empty([0]))\n",
    "    binB = bins[0]\n",
    "    binM = bins[1]\n",
    "\n",
    "    # obtaining the fields and LWI dataset (decaes or NNLS) & obtaining the ROIs for the data and the malignant ROI\n",
    "\n",
    "    fields, lwi, roi_all, roi_pz, roi_tz, gs_map = load_P_S(lwiPath, folder_roi, folder_pz, folder_gs, pnum, slice1)\n",
    "    \n",
    "    try:\n",
    "        if zone =='full':\n",
    "            roi_zone = roi_all\n",
    "        elif zone == 'pz':\n",
    "            roi_zone = roi_pz\n",
    "        elif zone == 'tz':\n",
    "            roi_zone = roi_tz\n",
    "    except:\n",
    "        print('Incorrect zone specified. Must be a subset of (full, \"pz\", or \"tz\"), not \"' + zone + '\".')\n",
    "        raise()\n",
    "\n",
    "    # For visualizing set-up (0/3)\n",
    "    if printGraphs:\n",
    "        plt.figure()\n",
    "        plt.rcParams['figure.figsize'] = (24, 8) # set default size of plots\n",
    "        f,ax = plt.subplots(2,len(parameters))\n",
    "        colours = np.array(sns.color_palette(palette=cname, n_colors=8))\n",
    "        # colour def 1\n",
    "#         ccc = sns.husl_palette(9).as_hex()\n",
    "#         colours = np.array([hex_to_rgb(ci.lstrip('#')) for ci in ccc])\n",
    "        # colour def 2\n",
    "#         colours = plt.cm.Set1(np.linspace(0,1,8))[:,0:3] # deciding colours of GS grading\n",
    "#         colours = colours[:,0:3]\n",
    "    else:\n",
    "        colours=None\n",
    "        ax = None\n",
    "\n",
    "    # looping through all the various parameters to concatenate the \"all\", \"benign\", and \"malignant\" pixels\n",
    "    for param in parameters:\n",
    "        \n",
    "        dataCompile, benignCompile, maligCompileTemp = getCompiledData(lwi, norm, dataCompile, benignCompile, maligCompile, roi_zone, gs_map, param, printGraphs,pnum,slice1,ax, int(parameters.index(param)-1),colours=colours)\n",
    "        newVals = dict.fromkeys(np.arange(6),np.empty([0])) # empty key\n",
    "        for m in maligCompile[param]: # compiling malig data\n",
    "            values = copy.deepcopy(maligCompile[param][m])\n",
    "            newVals[m] = np.concatenate((values,maligCompileTemp[m]),axis=0)\n",
    "        maligCompile.update({param:newVals})\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "    # For visualizing (3/3)\n",
    "    if printGraphs:\n",
    "        plt.figure()\n",
    "        plt.rcParams['figure.figsize'] = (20, 30) # set default size of plots\n",
    "        f,ax = plt.subplots(len(parameters),1)\n",
    "        for i,param in enumerate(parameters):\n",
    "            # Histograms\n",
    "            # -- benign\n",
    "            sns.histplot(benignCompile[param], bins = binB, color='dodgerblue', alpha=0.4, ax=ax[i-1],element=\"step\",kde=True)\n",
    "            # -- malig\n",
    "            for m in maligCompile[param]:\n",
    "                sns.histplot(maligCompile[param][m], bins = binM, color = colours[m+2,:],alpha=0.4,ax=ax[i-1],element=\"step\",kde=True)\n",
    "            # making legend\n",
    "            gs_labels = ['pz','tz','3+3','3+4','4+3','4+4','4+5','5+4']\n",
    "            legend_dict=dict(zip(gs_labels,colours))\n",
    "            patchList = [] #create patches\n",
    "            for key in legend_dict:\n",
    "                data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
    "                patchList.append(data_key)\n",
    "            patchListHist = patchList[2:]\n",
    "            patchListHist.append(mpatches.Patch(color='dodgerblue', label='benign'))\n",
    "            ax[i-1].legend(handles=patchListHist,fontsize='small')  \n",
    "            # making title\n",
    "            if norm == 'standardize' or norm == 'normalize' or norm == 'both':\n",
    "                ax[i-1].set_title('(Norm type: '+ norm+ '), P' + str(pnum) + ' S' + str(slice1) +', Param: ' + param + ', Zone: ' + zone, size=15)\n",
    "            else:\n",
    "                ax[i-1].set_title('P' + str(pnum) + ', Param: ' + param + ', Zone: ' + zone, size=15)\n",
    "        # saving data\n",
    "        if save:\n",
    "            if norm == 'standardize' or norm == 'normalize' or norm == 'both':\n",
    "                plt.savefig('P' + str(pnum)+ '_S' + str(slice1) + '_' + zone+ '_' + analysisType+ '_hist_' + norm + '.png')\n",
    "            else:\n",
    "                plt.savefig('P' + str(pnum)+ '_S' + str(slice1) + '_' + zone+ '_' + analysisType+ '_hist.png')\n",
    "    if printGraphs is False:\n",
    "        plt.close()\n",
    "\n",
    "    return dataCompile, benignCompile, maligCompile\n",
    "\n",
    "\n",
    "def hex_to_rgb(hex):\n",
    "    rgb = []\n",
    "    hex = hex[1:]\n",
    "    for i in (0, 2, 4):\n",
    "        decimal = int(hex[i:i+2], 16)/255\n",
    "        rgb.append(decimal)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0f157-dcce-4e12-b7fc-bd326f58b7c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions w/ Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56efa5-037f-42d8-b504-0656a367041b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------        \n",
    "# ----- sigmoid\n",
    "# --------------------------------  \n",
    "def sigmoid(x): \n",
    "    \"\"\"  Compute the sigmoid of x\n",
    "    Input:\n",
    "        x -- A scalar or numpy array of any size.\n",
    "    Return:\n",
    "        s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- tanh\n",
    "# --------------------------------  \n",
    "def tanh(x): \n",
    "    \"\"\"  Compute the tanh function of \n",
    "    Input:\n",
    "        x -- A scalar or numpy array of any size.\n",
    "    Return:\n",
    "        t -- tanh(x)\n",
    "    \"\"\"\n",
    "    t = np.tanh(x)\n",
    "    return t\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- normalize\n",
    "# --------------------------------  \n",
    "def normalize(M, normRange=None):\n",
    "    \"\"\" Normalize matrix M based to exist in [0,1] and removes nan's from calculation. Returns a matrix\n",
    "    Inputs:\n",
    "        - M:     matrix of size [n,m]\n",
    "        - normRange: a an array of size 1x2 that contains the max and min range [min, max]\n",
    "    Outputs:\n",
    "        - Mnorm: normalized matrix of size [n,m]\"\"\"\n",
    "    Mcopy = M[~np.isnan(M)]        \n",
    "    Mnorm = (M - np.min(Mcopy)) / (np.max(Mcopy) - np.min(Mcopy))\n",
    "    \n",
    "    if normRange is not None:\n",
    "        Mnorm = Mnorm*(normRange[1] - normRange[0]) + normRange[0]\n",
    "        \n",
    "    return Mnorm\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- standardize\n",
    "# --------------------------------  \n",
    "def standardize(M):\n",
    "    \"\"\" Standardize matrix M and removes nan's from calculation. Returns normalization as a vector\n",
    "    Inputs:\n",
    "        - M:    matrix of size [n,m]\n",
    "    Outputs:\n",
    "        - Mstd: normalized matrix of size [n,m]\"\"\"\n",
    "    Mcopy = M[~np.isnan(M)]  \n",
    "    Mstd = (M - np.mean(Mcopy)) / np.std(Mcopy)\n",
    "    return Mstd\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- outlineROI\n",
    "# --------------------------------  \n",
    "def outlineROI(mask):\n",
    "    # getting dilated outline of mask\n",
    "    kernSize = 2\n",
    "    kernel = np.ones((kernSize,kernSize), np.uint8)\n",
    "    img_outline = cv2.dilate(np.uint8(mask),kernel,iterations=1)-cv2.erode(np.uint8(mask),kernel,iterations=1)\n",
    "    return img_outline\n",
    "\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- findTopPlotParams\n",
    "# --------------------------------        \n",
    "def findTopPlotParams(benComp, malComp, parameters, show=False):\n",
    "    \"\"\" Finds the top 2 and top 3 parametesr to plot based on their largest differences (sigmoid + standrdization)\n",
    "    Inputs:\n",
    "    - benComp:    the benign component dictionary dataset\n",
    "    - malComp:    the malignant component dictionary dataset\n",
    "    - parameters: the string array of parameter names\n",
    "    - show:       to show the figures or not\n",
    "    Outputs:\n",
    "    - pltParams2: the top 2 parameters with the largest difference in mal/ben [string array]\n",
    "    - pltParams3: the top 3 parameters with the largest difference in mal/ben [string array]\"\"\"\n",
    "    diffs = np.zeros(len(parameters))\n",
    "    for i,param in enumerate(parameters):\n",
    "        if ~np.isclose(np.std(malComp[param][~np.isnan(malComp[param])]),0): \n",
    "            b = sigmoid((standardize(benComp[param][~np.isnan(benComp[param])])))\n",
    "            m =  sigmoid((standardize(malComp[param][~np.isnan(malComp[param])])))\n",
    "        else:\n",
    "            b = sigmoid(benComp[param][~np.isnan(benComp[param])])\n",
    "            m = sigmoid(malComp[param][~np.isnan(malComp[param])])\n",
    "        diffs[i] = np.abs(np.mean(b) - np.mean(m))\n",
    "        if show: \n",
    "        # Plotting\n",
    "            plt.figure()\n",
    "            sns.histplot(b, bins = 300, color='dodgerblue', alpha=0.4)\n",
    "            sns.histplot(m, bins = 100, color = 'coral',alpha=0.4)\n",
    "            plt.title(param)\n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0,7),diffs,'x')\n",
    "    \n",
    "    pltParams2 = ['','']\n",
    "    pltParams3 = ['','','']\n",
    "    pltParams2[0] = parameters[np.argmax(diffs)]\n",
    "    diffs[np.argmax(diffs)] = -1\n",
    "    pltParams2[1] = parameters[np.argmax(diffs)]\n",
    "    diffs[np.argmax(diffs)] = -1\n",
    "    pltParams3[0] = pltParams2[0]\n",
    "    pltParams3[1] = pltParams2[1]\n",
    "    pltParams3[2] = parameters[np.argmax(diffs)]\n",
    "    \n",
    "    return pltParams2, pltParams3\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- createXforPCA\n",
    "# --------------------------------  \n",
    "def createXforPCA(benComp, malComp, parameters):\n",
    "    \"\"\" Finding the default valid-pixel range length based on parameters given. Looks for smallest common denominator\n",
    "    Input:\n",
    "    - benComp:    the benign component dictionary dataset\n",
    "    - malComp:    the malignant component dictionary dataset\n",
    "    - parameters: the string array of parameter names\n",
    "    \n",
    "    Returns:\n",
    "    - X:   The concatenated matrix\n",
    "    \"\"\"\n",
    "    largestLen = np.zeros(len(parameters))\n",
    "    for i, param in enumerate(parameters): \n",
    "        largestLen[i] = len(benComp[param][~np.isnan(benComp[param])])+len(malComp[param][~np.isnan(malComp[param])])\n",
    "    default_pixel_length_param = parameters[np.argmin(largestLen)]\n",
    "    print('Minimum of set is the default valid-pixel range: ' + str((np.unique(largestLen))))\n",
    "\n",
    "    # Creating X matrix for SVD\n",
    "    X = np.zeros((int(largestLen[np.argmin(largestLen)]),len(parameters))) # initializing X matrix\n",
    "    labels = np.zeros((int(largestLen[np.argmin(largestLen)]),1)) #creating labels where 1 = cancer, 0 = benign\n",
    "    for i, param in enumerate(parameters): # X is a matrix of [n,p] n = #total pixels, p = # parameters. The first part of n is malignant, second part of n is benign\n",
    "        X[:,i] = (np.concatenate((malComp[param][~np.isnan(malComp[default_pixel_length_param])], benComp[param][~np.isnan(benComp[default_pixel_length_param])]),axis=0))\n",
    "    return X\n",
    "\n",
    "# --------------------------------        \n",
    "# ----- returnPCa_matrix\n",
    "# --------------------------------      \n",
    "def returnPCa_matrix(numPC, X, VT, labels):\n",
    "    \"\"\" Calculates the projection of matrix X in pricinple components and returns the benign and malignant data\n",
    "    Inputs:\n",
    "    - numPC:  the number of principal components to include\n",
    "    - X:      the original matrix\n",
    "    - VT:     the matrix containing principal axis\n",
    "    - labels: an array containing 1 = malignant, 0 = benign\n",
    "    \n",
    "    Outputs:\n",
    "    - X_pca: the matrix X projected in #numPC axis\n",
    "    - ben:   the portion of X_pca attributed to benign points\n",
    "    - mal:   the portion of X_pca attributed to malignant points\"\"\"\n",
    "    X_pca = np.zeros((len(labels),numPC))\n",
    "    newRow = np.zeros((1,numPC))\n",
    "\n",
    "    # looping through finding the principal components\n",
    "    for j in range(X.shape[0]):\n",
    "        for k in range(numPC):\n",
    "            X_pca[j,k] = np.dot(VT[k,:],X[j,:].T)\n",
    "    \n",
    "    # denoting which is benign and malignant        \n",
    "    ben = X_pca[int(sum(labels==1))::,:] # second part of data is benign\n",
    "    mal = X_pca[0:int(sum(labels==1))-1,:] # first part of data is malignant\n",
    "    \n",
    "    return X_pca, ben, mal\n",
    "\n",
    "def showSepHist(dat, param, roiB, roiMdict, ax1,ax2, leg, colours,dictkey,gs_labels):\n",
    "    bflag = True            \n",
    "    #    -- malig\n",
    "    for m in roiMdict:\n",
    "        dictkey[toSave[m+8]] = None\n",
    "        dictkey[toSave[m+14]]  = None\n",
    "        dictkey[toSave[m+20]]  = None\n",
    "        if np.sum(dat[roiMdict[m]][~np.isnan(dat[roiMdict[m]])]).astype(bool) & (np.sum(roiMdict[m])>15):\n",
    "            # setting range of histograms\n",
    "            binn = np.round((1 + 3.322*np.log(len(dat[roiB])+len(dat[roiMdict[m]])))).astype(int)\n",
    "            nnan1 = dat[roiB]; nnan1 = nnan1[~np.isnan(nnan1)]\n",
    "            nnan2 = dat[roiMdict[m]]; nnan2 = nnan2[~np.isnan(nnan2)]\n",
    "            ran = [min(np.min(nnan1),np.min(nnan2)), max(np.max(nnan1),np.max(nnan2))] \n",
    "            if nnan2 is float(\"inf\"):\n",
    "                ran = None\n",
    "                print('inf data. ')\n",
    "            if bflag:\n",
    "                ax = sns.histplot(dat[roiB], bins = binn, ax=ax1, color='dodgerblue', alpha=0.4,element=\"step\",binrange = ran,kde=True)\n",
    "                ax2 = sns.ecdfplot(dat[roiB], ax=ax2, color='dodgerblue')\n",
    "                bflag = False\n",
    "            ax = sns.histplot(dat[roiMdict[m]], bins = binn , ax=ax1, color = colours[m+2,:],alpha=0.4,element=\"step\",binrange = ran,kde=True)\n",
    "            ax2 = sns.ecdfplot(dat[roiMdict[m]], ax=ax2, color = colours[m+2,:])\n",
    "            \n",
    "            # counting overlap percentage\n",
    "            countB,binB = np.histogram(dat[roiB], bins=binn, range=ran)\n",
    "            countM,binM = np.histogram(dat[roiMdict[m]], bins=binn, range=ran)\n",
    "            ol = (np.sum(np.minimum(countB,countM)))\n",
    "            pol = ol/(np.sum(countM))\n",
    "            dictkey[toSave[m+8]] = pol.astype(float)\n",
    "            \n",
    "            # Get the two lines from the axes to generate shading\n",
    "            l1 = ax.lines[0]\n",
    "            l2 = ax.lines[-1]\n",
    "            # Get the xy data from the lines so that we can shade\n",
    "            x1, y1 = l1.get_xydata().T\n",
    "            x2, y2 = l2.get_xydata().T\n",
    "            # Calculating overlap\n",
    "            xmin = max(x1.min(), x2.min())\n",
    "            xmax = min(x1.max(), x2.max())\n",
    "            x = np.linspace(xmin, xmax, 1000)\n",
    "            y1a = np.interp(x, x1, y1)\n",
    "            y2a = np.interp(x, x2, y2)\n",
    "            y = np.minimum(y1a, y2a)\n",
    "#             axx.fill_between(x, y, color=\"red\", alpha=0.3)\n",
    "#             plt.plot(x,y)\n",
    "            area = trapz(y, dx=(x[-1]-x[0])/len(x))\n",
    "            perc = area / trapz(y2a, dx=(x[-1]-x[0])/len(x)) \n",
    "            dictkey[toSave[m+14]] = perc.astype(float)\n",
    "            \n",
    "            # Calculating inverted ROC for prediction intensity 1 == cancer\n",
    "            # if (param == 'N') or (param=='A2') or (param=='LWF') or (param=='gmT2') or (param=='T21'):\n",
    "            d1 = np.abs(1-dat[roiB]/max(np.max(dat[roiB]),np.max(dat[roiMdict[m]])))\n",
    "            d2 = np.abs(1-dat[roiMdict[m]]/max(np.max(dat[roiB]),np.max(dat[roiMdict[m]])))\n",
    "            # else:\n",
    "            #     d1 = dat[roiB]/max(np.max(dat[roiB]),np.max(dat[roiMdict[m]]))\n",
    "            #     d2 = dat[roiMdict[m]]/max(np.max(dat[roiB]),np.max(dat[roiMdict[m]]))\n",
    "            fpr, tpr, thresholds = roc_curve(np.concatenate([np.ones(np.shape(d2)), np.zeros(np.shape(d1))]), np.concatenate([d2,d1]))\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            dictkey[toSave[m+20]] = roc_auc.astype(float)\n",
    "#             plot_roc_curve(fpr, tpr, roc_auc,ccc=colours[m+2,:],lname=gs_labels[m+2],ax=ax nm32)\n",
    "    ax1.legend(handles=leg,fontsize='small');\n",
    "    return dictkey\n",
    "\n",
    " \n",
    "# --------------------------------        \n",
    "# ----- showSepHisto\n",
    "# --------------------------------      \n",
    "def showSepHisto(dat, param, roiB, roiMdict, ax, leg, colours):\n",
    "    sns.histplot(dat[roiB], bins = np.round(1 + 3.322*np.log(len(dat[roiB]))).astype(int), ax=ax, color='dodgerblue', alpha=0.4,element=\"step\",kde=True)\n",
    "    #    -- malig\n",
    "    for m in roiMdict:\n",
    "        if np.sum(dat[roiMdict[m]][~np.isnan(dat[roiMdict[m]])]).astype(bool):\n",
    "            sns.histplot(dat[roiMdict[m]], bins = np.round(1 + 3.322*np.log(len(dat[roiMdict[m]]))).astype(int), ax=ax, color = colours[m+2,:],alpha=0.4,element=\"step\",kde=True)\n",
    "    ax.legend(handles=leg,fontsize='small')   \n",
    "    \n",
    "# --------------------------------        \n",
    "# ----- plot_roc_curve\n",
    "# --------------------------------   \n",
    "def plot_roc_curve(fpr, tpr, roc_auc, lw=2,ccc=None,ax=None,lname='None'):\n",
    "    \"\"\"Plot roc curve\"\"\"\n",
    "    lw = lw\n",
    "    ax.plot(fpr, tpr, color=ccc,\n",
    "             lw=lw, label= lname + ', AUC=%0.2f' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic')\n",
    "    ax.legend(loc=\"lower right\")    \n",
    "\n",
    "# --------------------------------        \n",
    "# ----- getOutlineRoi\n",
    "# -------------------------------- \n",
    "def getOutlineRoi(mask, k=2):\n",
    "    \"\"\" Gets the outline of a binary mask \n",
    "    Input:\n",
    "        - mask: the binary mask\n",
    "        - k:    the kernel size\n",
    "    Return:\n",
    "        - mask_outline: returns a binary mask\"\"\"\n",
    "    # Specifying kernel size\n",
    "    kernel = np.ones((k,k), np.uint8)\n",
    "    mask = np.uint8(mask)\n",
    "    img_erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "    img_mod = cv2.dilate(img_erosion,kernel,iterations=1)\n",
    "    mask_outline = cv2.dilate(img_mod,kernel,iterations=1)-cv2.erode(img_mod,kernel,iterations=1)\n",
    "    return mask_outline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db0c0b-0ff7-4eab-b07d-5227ae4c53e9",
   "metadata": {},
   "source": [
    "# Testing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4a41f-07ec-4adb-b80a-60804b9fc726",
   "metadata": {},
   "source": [
    "#### Working Fn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96daf66-aab4-4523-85f6-f71baacd9e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runAnalysisWeightingGSmap(save, foldersavep, sheet, row2print, figShow, T2DecayPath, echo, lwipath, folder_roi, folder_pz, folder_gs, folder_HR, pnum, snum, norm, weights=1, cname='cubehelix'):\n",
    "    \"\"\"To show the image with weighting\n",
    "    Inputs:\n",
    "        - save:         whether or not to save figures \n",
    "        - foldersavep:\n",
    "        - row2print: \n",
    "        - figShow:      whether or not to show figures\n",
    "        - T2DecayPath:  path to T2 decay data (str)\n",
    "        - echo:         the echo number to get image from (int)\n",
    "        - lwiPath:      path to the LWI file folders (str)\n",
    "        - folder_roi:   path to the full ROI file folders (str) \n",
    "        - folder_pz:    path to the PZ ROI files (str)\n",
    "        - folder_gs:    path to the ROI files that malignancy levels based on GS (str)\n",
    "        - folder_HR:    path to the high-res T2W matlab files that are 512x512x18 (str)\n",
    "        - pnum:         the patient numbers (int array)\n",
    "        - snum:         specifying a slice for single pat + single slice analysis (int)\n",
    "        - norm:         normalize the values before concatenating (either standardize, normalize, or both)\n",
    "        - weighta:      weighting [array or int in []] on images where Im = normalize(Im*(1-weighting) + overlay*weighting)\n",
    "        - cname:        for the legend and viewing data\n",
    "    Returns:\n",
    "        - book:         an excel spreadsheet of the data collected\n",
    "        \"\"\"\n",
    "    # Settings for printing (individual pictures each)\n",
    "    plt.rcParams['figure.figsize'] = (10,10) # set default size of plots\n",
    "    plt.rcParams['image.cmap'] = 'gray'\n",
    "    \n",
    "    T2Decay = loadmat(glob.glob(T2DecayPath + '/P' + str(pnum).zfill(3) + '_cmplx*.mat')[0])\n",
    "    T2Decay = T2Decay[list(T2Decay.keys())[3]] # usually always the third item in loadmat!\n",
    "    \n",
    "    parameters,lwi = loadDecaesOrMatlab(lwiPath, pnum, snum)\n",
    "    roi_all, roi_pz, roi_tz, gs_map = loadROIall(folder_roi,folder_pz,folder_gs,pnum,snum)\n",
    "    zones = ['pz','tz','full','full_altWeight']\n",
    "    roi_zones=dict()\n",
    "    roi_zones['pz'] = roi_pz\n",
    "    roi_zones['tz'] = roi_tz\n",
    "    roi_zones['full'] = roi_all\n",
    "    \n",
    "#     roi[np.where(np.isclose(lwi['LWF'], 0))] = False\n",
    "#     roiM[np.where(np.isclose(lwi['LWF'], 0))] = False\n",
    "    \n",
    "    # Getting the ROIs of pz and tz\n",
    "    roiB=dict()\n",
    "    roiMdict=dict()\n",
    "    roi_t2w_save=dict()\n",
    "    roiB['pz'], roiMdict['pz'] = splitGS_roi(roi_pz, gs_map)\n",
    "    roiB['tz'], roiMdict['tz'] = splitGS_roi(roi_tz, gs_map)\n",
    "    roiB['full'], roiMdict['full'] = splitGS_roi(roi_all, gs_map)\n",
    "    \n",
    "    # T2 decay\n",
    "    img_decay=T2Decay[:,:,snum,echo] # the decay image\n",
    "    \n",
    "    \n",
    "    # Fig1 = showing image decay\n",
    "    plt.figure()\n",
    "    plt.imshow(img_decay)\n",
    "    plt.title('T2 Decay (' + str(np.size(img_decay,0)) + 'x' + str(np.size(img_decay,1)) + '). P' +str(pnum) + ' S' +str(snum)+ ' E' + str(echo) +'.' )\n",
    "    plt.axis('off')\n",
    "    if save:\n",
    "        plt.savefig(foldersavep +'/'+'P'+str(pnum) + '_S' +str(snum) +'_T2D.png')\n",
    "    if figShow:\n",
    "        plt.show()\n",
    "    \n",
    "    # Fig2 = showing malignancy\n",
    "    # setting defaults for figure\n",
    "    plt.figure()        \n",
    "    colours = np.array(sns.color_palette(palette=cname, n_colors=8))\n",
    "    # making legend\n",
    "    gs_labels = ['pz','tz','3+3','3+4','4+3','4+4','4+5','5+4']\n",
    "    legend_dict=dict(zip(gs_labels,colours))\n",
    "    patchList = []    #create patches\n",
    "    patchList.append(mpatches.Patch(color=legend_dict[gs_labels[0]], label=gs_labels[0]) ) #roi pz\n",
    "    patchList.append(mpatches.Patch(color=legend_dict[gs_labels[1]], label=gs_labels[1]) ) #roi tz\n",
    "    # getting oultines\n",
    "    pz_outline = outlineROI(roi_pz.astype(img_decay[0,0])).astype(bool)\n",
    "    tz_outline = outlineROI(roi_tz).astype(img_decay[0,0]).astype(bool)\n",
    "    baseim = np.dstack([(normalize(img_decay)),(normalize(img_decay)),(normalize(img_decay))]) # 3d image\n",
    "    for c in range(6):\n",
    "        baseim[(roi_pz|roi_tz)&(gs_map==c+1),:] = colours[c+2,:] # getting gs\n",
    "        if (np.sum(baseim[(roi_pz|roi_tz)&(gs_map==c+1),:])).astype(bool):\n",
    "            data_key = mpatches.Patch(color=legend_dict[gs_labels[c+2]], label=gs_labels[c+2]) \n",
    "            patchList.append(data_key)\n",
    "    # putting roi below all the grading \n",
    "    baseim[pz_outline,:] = colours[0,:] # getting pz outline\n",
    "    baseim[tz_outline,:] = colours[1,:] # getting tz outline\n",
    "    \n",
    "    plt.imshow(baseim)\n",
    "    plt.title('Gleason Grading & Zones')\n",
    "    plt.axis('off')\n",
    "    plt.legend(handles=patchList, fontsize='small');\n",
    "    if save:\n",
    "        plt.savefig(foldersavep +'/'+'P'+str(pnum) + '_S' +str(snum) +'_GSmap.png')\n",
    "    if figShow:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    # #################################\n",
    "    # ###########\n",
    "    # Getting the PCA image\n",
    "    # getting the weighting image inside just the full ROI\n",
    "    lwi_PCA = dict()\n",
    "    lwi_nonan = copy.deepcopy(lwi)\n",
    "    # for param in parameters:\n",
    "    #     lwi_nonan[param][~roi_all] = np.nan\n",
    "    origshape = np.shape(lwi_nonan[parameters[0]])\n",
    "    X_lwi = np.asarray((lwi_nonan[parameters[0]].flatten()))\n",
    "    pca_mean = np.mean(X_lwi[~(np.isnan(X_lwi))], axis=0)\n",
    "    for i,parami in enumerate(parameters[1:]):\n",
    "        X_temp = np.asarray(standardize(lwi_nonan[parami]).flatten())\n",
    "        X_lwi = np.vstack((X_lwi,X_temp))\n",
    "        pca_mean = np.append(pca_mean,np.mean(X_temp[~(np.isnan(X_temp))],axis=0))\n",
    "           \n",
    "    X_lwi = X_lwi.T\n",
    "    pca_transform_mat = dict()\n",
    "    pca_transform_mat['pz'] = np.array([[-0.47973739,  0.49448727,  0.4955605 , -0.04783564,  0.44775352, 0.26099344,  0.09415476]])\n",
    "    pca_transform_mat['tz'] = np.array([[-0.4510,    0.5161,    0.5176,    0.0954,    0.4221,    0.2315,    0.1464]])\n",
    "    pca_transform_mat['full'] = np.array([[-0.485654, 0.505522, 0.507955, 0.026392, 0.423345, 0.227122, 0.138086 ]])\n",
    "    # performing transformation\n",
    "    lwi_PCA['pz']= np.reshape(np.dot(X_lwi - pca_mean, pca_transform_mat['pz'].T), origshape)\n",
    "    lwi_PCA['tz']= np.reshape(np.dot(X_lwi - pca_mean, pca_transform_mat['tz'].T), origshape)\n",
    "    lwi_PCA['full']= np.reshape(np.dot(X_lwi - pca_mean, pca_transform_mat['pz'].T), origshape)\n",
    "    \n",
    "    # ###########\n",
    "    # ####################################\n",
    "    \n",
    "    # looping through weights:\n",
    "    firstweightflag = 0\n",
    "    \n",
    "    try:\n",
    "        for weighting in weights:\n",
    "            weightPath = makeDir(foldersavep+'/W_'+str(weighting))\n",
    "            hr_full_savePZ = dict()\n",
    "            for zonei, zone in enumerate(zones):\n",
    "                # ---- adding directory for a zone (new folder)\n",
    "                zonePath = makeDir(weightPath+'/'+zone)\n",
    "\n",
    "                if zonei == 3: # this means we're in iterating to the \"full\" roi\n",
    "                    zone = 'tz'\n",
    "                    beforesave = save\n",
    "                    save = False\n",
    "\n",
    "                # ---- plot & histogram\n",
    "                roi_zone = roi_zones[zone]\n",
    "                row2print['Patient'] = float(pnum)\n",
    "                row2print['Slice'] = float(snum)\n",
    "                row2print['Echo'] = echo\n",
    "                row2print['Norm?'] = norm\n",
    "                row2print['Weighting %'] = float(weighting)\n",
    "                row2print['Zone'] = zone\n",
    "\n",
    "\n",
    "                # the malig rois split by GS as a dictionary. 0-->'3+3', 1--> '3+4', etc. [dict]\n",
    "                dataCompile, benignCompile, maligCompile = load_single_patient_datacompile1(lwiPath, folder_roi, folder_pz, folder_gs, zone, pnum, snum, parameters, norm=norm, printGraphs=False,save=False)\n",
    "\n",
    "                # weighted image\n",
    "                param = 'PCA(std)'\n",
    "\n",
    "                # getting the weighting image inside just the full ROI\n",
    "                img2 = copy.deepcopy(lwi_PCA[zone])\n",
    "                if np.isnan(np.sum((img2[roi_zone]))):\n",
    "                    roi_zone[np.isnan(img2*roi_zone)] = False\n",
    "                img2[~roi_zone] = np.nan # removing background!\n",
    "\n",
    "                # required for scaling of image properly when weighting\n",
    "                tempIm = copy.deepcopy(img_decay)\n",
    "                tempIm = (tempIm - min(img_decay[roi_zone]))/(max(img_decay[roi_zone])-min(img_decay[roi_zone]))            \n",
    "\n",
    "                # Obtaining weighting images\n",
    "                # --- Tanh on Standardized\n",
    "                w_tstand = normalize(img_decay)\n",
    "                w_temp = tanh(standardize(img2))    \n",
    "                new_w_temp = tempIm*(1-weighting) + normalize(tempIm*w_temp)*weighting\n",
    "                new_w_temp = normalize(new_w_temp, [min(w_tstand[roi_zone]),max(w_tstand[roi_zone])])\n",
    "                w_tstand[roi_zone] = new_w_temp[roi_zone]\n",
    "\n",
    "                # --- sigmoid on Standardized\n",
    "                w_sstand = normalize(img_decay)\n",
    "                w_temp = sigmoid(standardize(img2))    \n",
    "                new_w_temp = tempIm*(1-weighting) + normalize(tempIm*w_temp)*weighting\n",
    "                new_w_temp = normalize(new_w_temp, [min(w_tstand[roi_zone]),max(w_tstand[roi_zone])])\n",
    "                w_sstand[roi_zone] = new_w_temp[roi_zone]\n",
    "\n",
    "                # Showing figures\n",
    "                plt.rcParams['figure.figsize'] = (30,20) # set default size of plots\n",
    "                plt.figure()\n",
    "                f,ax = plt.subplots(3,4)\n",
    "                ax[0,0].imshow(img2)\n",
    "                ax[0,0].set_title('Zone: ' + zone + ', Param: ' +param)\n",
    "                ax[0,0].axis('off')\n",
    "\n",
    "                ax[0,1].imshow(img_decay)\n",
    "                ax[0,1].set_title('T2W image')\n",
    "                ax[0,1].axis('off')\n",
    "\n",
    "                ax[0,2].imshow(w_tstand)\n",
    "                ax[0,2].set_title('Tanh + Standardized')\n",
    "                ax[0,2].axis('off')\n",
    "\n",
    "                ax[0,3].imshow(w_sstand)\n",
    "                ax[0,3].set_title('Sigmoid + Standardized')\n",
    "                ax[0,3].axis('off')\n",
    "                #^------------------------------------^  \n",
    "                # ########################################\n",
    "                ###########\n",
    "                if firstweightflag == 0:\n",
    "                    firstweightflag = 1\n",
    "                    # Call to Matlab to get high-res images\n",
    "                    # Note: the matlab function needs to be in the same folder as the working folder of the python script being run\n",
    "                    # output of the function is a \"struct\" with two variables 't2w_roi' and 't2w_slice'\n",
    "                    eng = matlab.engine.start_matlab()\n",
    "                    matlab_struct = eng.fn_runApp(matlab.double(int(pnum)), matlab.double(int(snum)), matlab.double(roi_all.tolist()), matlab.double(lwi_PCA[zone].tolist()), nargout = 1)\n",
    "                    if len(matlab_struct['t2w_roi'])==0:\n",
    "                        raise NameError('Cancelled')\n",
    "                    \n",
    "                    # getting the high-res ROI and silce\n",
    "                    hr_roi_full = np.array(matlab_struct['t2w_roi'])\n",
    "                    hr_slice = int(matlab_struct['t2w_slice'])-1\n",
    "                    imweight = matlab_struct['weight']\n",
    "                    # high-res T2W images\n",
    "                    hr_img = loadHR_T2W(folder_HR, pnum, hr_slice)\n",
    "                    orig_hr_img = copy.deepcopy(hr_img)\n",
    "                    # saving figure\n",
    "                    imageio.imwrite(foldersavep +'/P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_slice_'+ str(hr_slice+1) + '.png', np.uint8(hr_roi_full)*255)\n",
    "                    imageio.imwrite(foldersavep +'/P'+str(pnum)+'_S' +str(snum)+'_T2W_slice_'+ str(hr_slice+1) + '.png', np.uint8(hr_img/hr_img.max()*255))\n",
    "\n",
    "                    # getting points of the small rectangle of roi (rx/ry) and larger roi (nx/ny)\n",
    "                    rx1 = int(matlab_struct['dimSmall']['x1'])-1\n",
    "                    rx2 = int(matlab_struct['dimSmall']['x2'])\n",
    "                    ry1 = int(matlab_struct['dimSmall']['y1'])-1\n",
    "                    ry2 = int(matlab_struct['dimSmall']['y2'])\n",
    "                    nx1 = np.min(np.where(hr_roi_full)[0])\n",
    "                    nx2 = np.max(np.where(hr_roi_full)[0])+1\n",
    "                    ny1 = np.min(np.where(hr_roi_full)[1])\n",
    "                    ny2 = np.max(np.where(hr_roi_full)[1])+1\n",
    "\n",
    "                    hr_subroi=dict()\n",
    "                    hr_subroi['full'] = ski_resize(roi_all[rx1:rx2, ry1:ry2], [nx2-nx1,ny2-ny1], anti_aliasing=False)\n",
    "                    hr_subroi['pz'] = ski_resize(roi_pz[rx1:rx2, ry1:ry2], [nx2-nx1,ny2-ny1], anti_aliasing=False)\n",
    "                    hr_subroi['tz'] = ski_resize(roi_tz[rx1:rx2, ry1:ry2], [nx2-nx1,ny2-ny1], anti_aliasing=False)\n",
    "\n",
    "\n",
    "                    hr_roi=dict()\n",
    "                    hr_roi['pz'] = np.zeros(np.shape(hr_img))\n",
    "                    hr_roi['tz'] = np.zeros(np.shape(hr_img))\n",
    "                    hr_roi['full'] = hr_roi_full\n",
    "                    hr_roi['pz'][nx1:nx2,ny1:ny2] = hr_subroi['pz']\n",
    "                    hr_roi['tz'][nx1:nx2,ny1:ny2] = hr_subroi['tz']\n",
    "                    hr_roi['full'] = hr_roi['full']>0\n",
    "                    hr_roi['pz']   = hr_roi['pz']>0\n",
    "                    hr_roi['tz']   = hr_roi['tz']>0\n",
    "                else:\n",
    "                    hr_img = copy.deepcopy(orig_hr_img)\n",
    "                    \n",
    "                # --- PCA on T2W High-Res 512x512 images\n",
    "                if zonei == 3:\n",
    "                    hr_img = copy.deepcopy(hr_full_savePZ[param])\n",
    "                tempIm_hr = copy.deepcopy(hr_img)\n",
    "                tempIm_hr = (tempIm_hr - min(hr_img[hr_roi[zone]]))/(max(hr_img[hr_roi[zone]])-min(hr_img[hr_roi[zone]]))\n",
    "                # obtaining the PCA image\n",
    "                img2 = copy.deepcopy(lwi_PCA[zone])\n",
    "                if np.isnan(np.sum((img2[roi_zone]))):\n",
    "                    roi_zone[np.isnan(img2*roi_zone)] = False \n",
    "                # not removing nans from pca image \n",
    "                ssub_im = ski_resize(img2[rx1:rx2, ry1:ry2], [nx2-nx1,ny2-ny1], anti_aliasing=False)\n",
    "                clippedROIt2w = hr_subroi[zone]>0\n",
    "                ssub_im[~clippedROIt2w] = np.nan\n",
    "\n",
    "                hr_w_tstand = normalize(hr_img)\n",
    "                w_temp_hr_sub = tanh(standardize(ssub_im))    \n",
    "                new_w_temp = tempIm_hr[nx1:nx2,ny1:ny2]*(1-weighting) + normalize(tempIm_hr[nx1:nx2,ny1:ny2]*w_temp_hr_sub)*weighting\n",
    "                new_w_temp = normalize(new_w_temp, [min(hr_w_tstand[hr_roi[zone]]),max(hr_w_tstand[hr_roi[zone]])])\n",
    "                hr_overlay_sub = hr_w_tstand[nx1:nx2,ny1:ny2]\n",
    "                hr_overlay_sub[clippedROIt2w] = new_w_temp[clippedROIt2w]\n",
    "                hr_w_tstand[nx1:nx2,ny1:ny2] = hr_overlay_sub\n",
    "                if zone == 'pz':\n",
    "                    hr_full_savePZ[param] = copy.deepcopy(hr_w_tstand) # making a copy to save in pz and then combine with tz later for the \"full\"\n",
    "                \n",
    "                if figShow:\n",
    "                    plt.figure()\n",
    "                    plt.rcParams['figure.figsize'] = (10,10) # set default size of plots\n",
    "                    plt.imshow(np.array(matlab_struct['outputHR']))\n",
    "                else:\n",
    "                    plt.close()\n",
    "                # imageio.imwrite(zonePath +'/Overlay_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_'+zone+'_slice_'+ str(hr_slice+1) + '_w' +str(weighting) + '_PCA.png', (np.array(matlab_struct['outputHR'])*255).astype(np.uint8))\n",
    "                if zonei == 3:\n",
    "                        imageio.imwrite(zonePath +'/Overlay_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_full_slice_'+ str(hr_slice) + '_w' +str(weighting) + '_' + param +'.png', (hr_w_tstand*255).astype(np.uint8))\n",
    "                else:\n",
    "                    imageio.imwrite(zonePath +'/Overlay_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_'+zone+'_slice_'+ str(hr_slice) + '_w' +str(weighting) + '_' + param +'.png', (hr_w_tstand*255).astype(np.uint8))\n",
    "\n",
    "                ###########\n",
    "                # ########################################\n",
    "                #^------------------------------------^  \n",
    "\n",
    "                # analysis\n",
    "                # Analysis of weighted - Histograms ------------------------------------,\n",
    "                # making legend & colours\n",
    "                colours = np.array(sns.color_palette(palette=cname, n_colors=8))\n",
    "                patchList = [] #create patches\n",
    "                patchList.append(mpatches.Patch(color='dodgerblue', label='Benign'))\n",
    "                for m in maligCompile['LWF']:\n",
    "                    if np.sum(maligCompile['LWF'][m][~np.isnan(maligCompile['LWF'][m])]).astype(bool):\n",
    "                        data_key = mpatches.Patch(color=legend_dict[gs_labels[m+2]], label=gs_labels[m+2]) \n",
    "                        patchList.append(data_key)\n",
    "\n",
    "                if zonei < 3:\n",
    "                    row2print['Param'] = param\n",
    "                    # --- Original T2W\n",
    "                    row2print = showSepHist(img_decay,param,roiB[zone],roiMdict[zone],ax[1,1], ax[2,1],patchList, colours,row2print,gs_labels)\n",
    "                    row2print['Weighting fn'] = 'Original'\n",
    "                    sheet = excel_output(sheet,toSave,row2print)\n",
    "\n",
    "                    # --- Tanh on Standardized\n",
    "                    row2print = showSepHist(w_tstand,param,roiB[zone],roiMdict[zone],ax[1,2], ax[2,2],patchList, colours,row2print,gs_labels)\n",
    "                    row2print['Weighting fn'] = 'Tanh'\n",
    "                    sheet = excel_output(sheet,toSave,row2print)\n",
    "\n",
    "                    # --- sigmoid on Standardized\n",
    "                    row2print = showSepHist(w_sstand,param,roiB[zone],roiMdict[zone],ax[1,3], ax[2,3],patchList, colours,row2print,gs_labels)\n",
    "                    row2print['Weighting fn'] = 'Sigmoid'\n",
    "                    sheet = excel_output(sheet,toSave,row2print)\n",
    "                    \n",
    "                    ax[1,0].imshow(baseim)\n",
    "                    ax[1,0].set_title('Gleason Grading & Zones')\n",
    "                    ax[1,0].axis('off')\n",
    "                    ax[1,0].legend(handles=patchList, fontsize='small');\n",
    "                    f.delaxes(ax[2,0])\n",
    "                if save:\n",
    "                    imageio.imwrite(zonePath +'/LR_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_'+zone+'_w' +str(weighting) + '_' + param +'.png', (w_tstand*255).astype(np.uint8))\n",
    "                    # plt.savefig(zonePath +'/'+'P'+str(pnum) + '_S' +str(snum) + '_'+param+'_w' +str(imweight) + '_' + zone + '.png')\n",
    "                if figShow:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "                # printing out LWI parameter values\n",
    "                for i,param in enumerate(parameters):       \n",
    "\n",
    "                    # weighted image\n",
    "                    overlayIm = lwi[param]\n",
    "\n",
    "                    # getting the weighting image inside just the full ROI\n",
    "                    img2=copy.deepcopy(overlayIm) \n",
    "                    if np.isnan(np.sum((img2[roi_zone]))):\n",
    "                        roi_zone[np.isnan(img2*roi_zone)] = False\n",
    "                    img2[~roi_zone] = np.nan # removing background!\n",
    "\n",
    "                    # required for scaling of image properly when weighting\n",
    "                    tempIm = copy.deepcopy(img_decay)\n",
    "                    tempIm = (tempIm - min(img_decay[roi_zone]))/(max(img_decay[roi_zone])-min(img_decay[roi_zone]))\n",
    "\n",
    "                    # Obtaining weighting images\n",
    "                    # --- Tanh on Standardized\n",
    "                    w_tstand = normalize(img_decay)\n",
    "                    w_temp = tanh(standardize(img2))    \n",
    "                    new_w_temp = tempIm*(1-weighting) + normalize(tempIm*w_temp)*weighting\n",
    "                    new_w_temp = normalize(new_w_temp, [min(w_tstand[roi_zone]),max(w_tstand[roi_zone])])\n",
    "                    w_tstand[roi_zone] = new_w_temp[roi_zone]\n",
    "\n",
    "                    # --- sigmoid on Standardized\n",
    "                    w_sstand = normalize(img_decay)\n",
    "                    w_temp = sigmoid(standardize(img2))    \n",
    "                    new_w_temp = tempIm*(1-weighting) + normalize(tempIm*w_temp)*weighting\n",
    "                    new_w_temp = normalize(new_w_temp, [min(w_tstand[roi_zone]),max(w_tstand[roi_zone])])\n",
    "                    w_sstand[roi_zone] = new_w_temp[roi_zone]\n",
    "\n",
    "                    # Showing figures\n",
    "                    plt.rcParams['figure.figsize'] = (30,20) # set default size of plots\n",
    "                    plt.figure()\n",
    "                    f,ax = plt.subplots(3,4)\n",
    "                    ax[0,0].imshow(img2)\n",
    "                    ax[0,0].set_title('Zone: ' + zone + ', Param: ' +param)\n",
    "                    ax[0,0].axis('off')\n",
    "\n",
    "                    ax[0,1].imshow(img_decay)\n",
    "                    ax[0,1].set_title('T2W image')\n",
    "                    ax[0,1].axis('off')\n",
    "\n",
    "                    ax[0,2].imshow(w_tstand)\n",
    "                    ax[0,2].set_title('Tanh + Standardized')\n",
    "                    ax[0,2].axis('off')\n",
    "\n",
    "                    ax[0,3].imshow(w_sstand)\n",
    "                    ax[0,3].set_title('Sigmoid + Standardized')\n",
    "                    ax[0,3].axis('off')\n",
    "                    #^------------------------------------^  \n",
    "                    # --- PCA on T2W High-Res 512x512 images\n",
    "                    # high-res T2W images\n",
    "                    if zonei == 3:\n",
    "                        hr_img = copy.deepcopy(hr_full_savePZ[param])\n",
    "                    tempIm_hr = copy.deepcopy(hr_img)\n",
    "                    tempIm_hr = (tempIm_hr - min(hr_img[hr_roi[zone]]))/(max(hr_img[hr_roi[zone]])-min(hr_img[hr_roi[zone]]))\n",
    "                    # obtaining the PCA image\n",
    "                    img2 = copy.deepcopy(overlayIm)\n",
    "                    if np.isnan(np.sum((img2[roi_zone]))):\n",
    "                        roi_zone[np.isnan(img2*roi_zone)] = False \n",
    "                    # not removing nans from pca image \n",
    "                    ssub_im = ski_resize(img2[rx1:rx2, ry1:ry2], [nx2-nx1,ny2-ny1], anti_aliasing=False)\n",
    "                    clippedROIt2w = hr_subroi[zone]>0\n",
    "                    ssub_im[~clippedROIt2w] = np.nan\n",
    "\n",
    "                    hr_w_tstand = normalize(hr_img)\n",
    "                    w_temp_hr_sub = tanh(standardize(ssub_im))    \n",
    "                    new_w_temp = tempIm_hr[nx1:nx2,ny1:ny2]*(1-weighting) + normalize(tempIm_hr[nx1:nx2,ny1:ny2]*w_temp_hr_sub)*weighting\n",
    "                    new_w_temp = normalize(new_w_temp, [min(hr_w_tstand[hr_roi[zone]]),max(hr_w_tstand[hr_roi[zone]])])\n",
    "                    hr_overlay_sub = hr_w_tstand[nx1:nx2,ny1:ny2]\n",
    "                    hr_overlay_sub[clippedROIt2w] = new_w_temp[clippedROIt2w]\n",
    "                    hr_w_tstand[nx1:nx2,ny1:ny2] = hr_overlay_sub\n",
    "                    if zone == 'pz':\n",
    "                        hr_full_savePZ[param] = copy.deepcopy(hr_w_tstand) # making a copy to save in pz and then combine with tz later for the \"full\"\n",
    "                    \n",
    "                    if figShow:\n",
    "                        plt.figure()\n",
    "                        plt.rcParams['figure.figsize'] = (10,10) # set default size of plots\n",
    "                        plt.imshow(hr_w_tstand)\n",
    "                    else:\n",
    "                        plt.close()\n",
    "                    if zonei == 3:\n",
    "                        imageio.imwrite(zonePath +'/Overlay_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_full_slice_'+ str(hr_slice) + '_w' +str(weighting) + '_' + param +'.png', (hr_w_tstand*255).astype(np.uint8))\n",
    "                    else:\n",
    "                        imageio.imwrite(zonePath +'/Overlay_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_'+zone+'_slice_'+ str(hr_slice) + '_w' +str(weighting) + '_' + param +'.png', (hr_w_tstand*255).astype(np.uint8))\n",
    "                    #^------------------------------------^  \n",
    "\n",
    "                    # analysis\n",
    "                    # Analysis of weighted - Histograms ------------------------------------,\n",
    "                    # making legend & colours\n",
    "                    colours = np.array(sns.color_palette(palette=cname, n_colors=8))\n",
    "                    patchList = [] #create patches\n",
    "                    patchList.append(mpatches.Patch(color='dodgerblue', label='Benign'))\n",
    "                    for m in maligCompile[param]:\n",
    "                        if np.sum(maligCompile[param][m][~np.isnan(maligCompile[param][m])]).astype(bool):\n",
    "                            data_key = mpatches.Patch(color=legend_dict[gs_labels[m+2]], label=gs_labels[m+2]) \n",
    "                            patchList.append(data_key)\n",
    "                    if zonei < 3:\n",
    "                        row2print['Param'] = param\n",
    "                        # --- Tanh on Standardized\n",
    "                        row2print = showSepHist(w_tstand,param,roiB[zone],roiMdict[zone],ax[1,2], ax[2,2],patchList, colours,row2print,gs_labels)\n",
    "                        row2print['Weighting fn'] = 'Tanh'\n",
    "                        sheet = excel_output(sheet,toSave,row2print)\n",
    "\n",
    "                        # --- sigmoid on Standardized\n",
    "                        row2print = showSepHist(w_sstand,param,roiB[zone],roiMdict[zone],ax[1,3], ax[2,3],patchList, colours,row2print,gs_labels)\n",
    "                        row2print['Weighting fn'] = 'Sigmoid'\n",
    "                        sheet = excel_output(sheet,toSave,row2print)\n",
    "                        \n",
    "                        ax[1,0].imshow(baseim)\n",
    "                        ax[1,0].set_title('Gleason Grading & Zones')\n",
    "                        ax[1,0].axis('off')\n",
    "                        ax[1,0].legend(handles=patchList, fontsize='small');\n",
    "                        f.delaxes(ax[2,0])\n",
    "                    if save:\n",
    "                        imageio.imwrite(zonePath +'/LR_P'+str(pnum)+'_S' +str(snum)+'_T2Wroi_zone_'+zone+'_w' +str(weighting) + '_' + param +'.png', (w_tstand*255).astype(np.uint8))\n",
    "                        # plt.savefig(zonePath +'/'+'P'+str(pnum) + '_S' +str(snum) + '_'+param+'_Weighted_' + zone + '.png')\n",
    "                    if figShow:\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        plt.close()\n",
    "                \n",
    "                if zonei == 3:\n",
    "                    save = beforesave # reverting what the save flag was before!\n",
    "\n",
    "    except NameError:\n",
    "        print('Skipping P' + str(pnum) + ' S' +str(snum))\n",
    "        shutil.rmtree(foldersavep)\n",
    "    except:\n",
    "        print('Error using min/max with current roi zone: ' + zone + ', number of values: ' + str(np.sum(img_decay[roi_zone])))\n",
    "        raise\n",
    "    return book, parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed44b2-2f69-4523-8521-589ca0c616c7",
   "metadata": {},
   "source": [
    "#### WIP Fn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dde92f-3cbd-44f1-8804-f167faf9a916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import xlwt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import shutil\n",
    "from numpy import trapz\n",
    "plt.figure().clear()\n",
    "plt.close()\n",
    "\n",
    "patNumList = [70] # np.arange(70,71)##np.arange(65,110+1) # \n",
    "snum = '7'\n",
    "echo = 4\n",
    "weight = [0.75]\n",
    "weights = [0.75] #np.linspace(0,1,5)\n",
    "saveFiles = True\n",
    "figShow = True\n",
    "cmap = 'Set1' #cubehelix\n",
    "lwiPath = folder_nnls_decaes #_matlab # or decaes\n",
    "norm = None\n",
    "\n",
    "foldersavep = \"C:/Users/candi/Documents/Research/10 Thesis/Figures/analysis/\" #need \"/\" after\n",
    "outputPath = makeDir(foldersavep+'/'+'Aug14')\n",
    "saveExcel = 'analysisLV4.xls'\n",
    "toSave = ['Patient','Slice','Echo', 'Zone','Norm?','Weighting %','Param','Weighting fn',\\\n",
    "          'Hist OVL (3+3)','Hist OVL (3+4)','Hist OVL (4+3)','Hist OVL (4+4)','Hist OVL (4+5)','Hist OVL (5+4)', \\\n",
    "          'KDE (3+3)','KDE (3+4)','KDE (4+3)','KDE (4+4)','KDE (4+5)','KDE (5+4)', \\\n",
    "          'AUC (3+3)','AUC (3+4)','AUC (4+3)','AUC (4+4)','AUC (4+5)','AUC (5+4)']\n",
    "\n",
    "# initializing dictionary to save to excel\n",
    "book,sheet = init_excel(toSave)\n",
    "row2print = dict(zip(toSave, [None]*len(toSave)))\n",
    "\n",
    "try:\n",
    "    for p,pnum in enumerate(patNumList):\n",
    "        pnum=int(pnum)\n",
    "        patdirs = glob.glob(folder_roi+'/P*' + str(pnum) + '*') # getting the files that contain the patient number for the ROIs\n",
    "        slices = [] # array that carries the slices available for the patient\n",
    "        if patdirs:\n",
    "            pnumPath = makeDir(outputPath+'/'+'P' + str(pnum))\n",
    "\n",
    "        # # looping through the patient's slices\n",
    "        # snums = []\n",
    "        # for sliceFile in patdirs: # to keep things in order\n",
    "        #     snums.append(re.compile(\"(?<=_S)\\d*(?!>_)\").findall(sliceFile)[0])\n",
    "        #     snum_int = [int(x) for x in snums]\n",
    "        #     snum_int.sort()\n",
    "        #     snums = [str(x) for x in snum_int]\n",
    "        # for snum in snums:\n",
    "            snumPath = makeDir(pnumPath + '/S' + snum)\n",
    "            book,parameters = runAnalysisWeightingGSmap(saveFiles,snumPath, sheet, row2print, figShow, T2Decay_data_folder, echo, lwiPath, folder_roi, folder_pz, folder_gs, HR_T2W_data_folder, pnum, int(snum), norm, weights, cmap)\n",
    "            # printParamsAllROIs(T2Decay_data_folder, echo, lwiPath, folder_roi, folder_pz, folder_gs, pnum, int(snum), parameters, cname=None, save=False, analysisType='both')\n",
    "                \n",
    "\n",
    "    # Saving book to excel only if there are files\n",
    "    if os.listdir(outputPath):\n",
    "        book.save(outputPath + '/' + saveExcel)\n",
    "        print('Analysis Finished. Location: ', outputPath)\n",
    "    else:\n",
    "        os.rmdir(outputPath)\n",
    "        print('No files found to analyze.')\n",
    "        shutil.rmtree(outputPath) # delete folder if error arises\n",
    "except:\n",
    "    book.save(outputPath + '/' + saveExcel)\n",
    "    # shutil.rmtree(outputPath) # delete entire analysis folder if error arises\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana-env",
   "language": "python",
   "name": "ana-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
